### Ollama新版本来袭：优化升级，让AI对话更流畅

#### 引言：

随着人工智能技术的不断进步，大型语言模型（LLM）在对话问答和检索增强生成领域的应用越来越广泛。Ollama，作为领先的开源框架，致力于让本地运行LLM变得更加简单。最近，Ollama团队发布了两个重要更新，让我们一探究竟。

#### 更新亮点：

- **版本0.1.35**：新增ChatQA-1.5模型支持，为对话式问答带来革命性的进步。
- **版本0.1.36**：针对Windows平台的AMD显卡用户，修复了关键的exit status错误，同时解决了CPU运行时的内存不足问题。

#### 为什么需要更新？

- 修复的bug可以显著提升用户体验，避免在使用过程中遇到的不必要麻烦。
- 新增的ChatQA-1.5模型将增强对话问答的准确性和流畅性，为研究和开发带来新的可能。

#### 如何升级Ollama？

- **macOS和Windows用户**：享受自动更新的便利，通过点击任务栏或菜单栏图标，选择“重启以更新”即可。
- **Linux用户**：通过简单的命令行操作，快速完成更新，保持框架的前沿性。

#### Ollama的应用场景：

- **研究**：深入探索LLM的行为和性能。
- **开发**：构建基于LLM的创新应用程序。
- **教育**：教育领域中，Ollama是理解LLM的有力工具。
- **娱乐**：与LLM进行互动，享受聊天和游戏的乐趣。

#### 结语：

Ollama的新版本不仅修复了关键问题，还通过引入新的模型，为AI对话领域带来了新的活力。无论是研究人员、开发者、教育工作者还是普通用户，都能从这次更新中获益。立即升级，体验更流畅的AI对话吧！

## 

**参考文献**

[1]. RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE: https://arxiv.org/pdf/2401.08406.pdf

[2]. Gorilla LLM  [GitHub - ShishirPatil/gorilla: Gorilla: An API store for LLMs](https://github.com/ShishirPatil/gorilla)

[3]. RAFT: Adapting Language Model to Domain Specific RAG: https://gorilla.cs.berkeley.edu/blogs/9_raft.html
