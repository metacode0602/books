    Ollama v0.1.33版本携革新之风，为本地大型模型运行带来突破性升级。在此次更新中，不仅修复了众多潜在的系统中断与性能瓶颈问题，更精心打磨了Ollama的核心组件，显著降低了内存占用，同时提升了处理速度，确保了系统的稳健与响应的迅捷。此外，Ollama v0.1.33版本还扩展了对多样大型语言模型（LLM）的支持，使用户能够轻松部署和驾驭更广泛的预训练模型，进一步拓宽了本地模型应用的边界。这不仅是一次技术的飞跃，更是对用户体验的深刻洞察与提升。让我们看看本次更新的亮点吧。

更新亮点

    此次版本更新的核心亮点在于其新增的多并发功能，允许多个用户在同一台宿主机上与LLMs进行互动，实现同时聊天对话。这对于企业或团队用户来说，无疑是一个巨大的福音，因为它不仅提高了本地协作效率，还优化了用户体验。

模型增加

此版本还增加了多个新的LLM型号，包括但不限于：

- Llama 3：由Meta推出的新模型，迄今为止最强大的公开可用的大型语言模型（LLM）。

- Phi 3 Mini：由微软推出的新型3.8B参数、轻量级、尖端开放模型。

- Moondream：一款小巧精悍、无所不能的视觉语言模型​，专为在边缘设备上高效运行而设计的一款小型视觉语言模型。

- Llama 3 Gradient 1048K：由Gradient微调的Llama 3模型，支持高达100万个令牌的上下文窗口。

- Dolphin Llama 3：基于Llama 3的无审查Dolphin模型，由Eric Hartford训练，具备多种指令、对话和编码技能。

- Qwen 110B：首个超过100B参数大小的Qwen模型，在评估中表现出色。

- Llama 3 Gradient：对Llama 3的微调，支持高达100万个令牌的上下文窗口。

修复与改进

    Ollama团队还修复了一些关键问题，如模型不终止导致的API挂起问题，以及在Apple Silicon Mac上出现的内存溢出错误。此外，还针对Mixtral架构模型的内存溢出问题进行了修复。

实验性并发特性

    新版本引入了实验性的并发特性，通过设置环境变量，可以为单个模型同时处理多个请求，并同时加载多个模型。这些特性可以通过以下环境变量来设置：

- *OLLAMA_NUM_PARALLEL*：并行处理请求的数量。

- *OLLAMA_MAX_LOADED_MODELS*：同时加载的模型数量。

设置并发及加载多个模型

    在Linux上设置并发及加载多个模型的详细步骤。对于Windows 11，用户需要通过系统设置来添加新的环境变量。而在Linux上，则需要编辑systemd服务文件来添加环境变量。

测试与效果

    在多模型运行功能未启用之前，用户与单一模型的对话是以队列形式进行的。启用新功能后，对话能够并行处理，显著提升了内网环境下多用户协同与一个或多个模型进行对话的效率。

结语

    Ollama v0.1.33版本的更新，不仅在技术上实现了突破，更在用户体验上做了深入的优化。无论是新增的模型、修复的问题，还是实验性的并发特性，都显示了Ollama团队对提升产品性能和用户满意度的承诺。对于希望在本地部署并高效利用大型语言模型的企业和开发者来说，Ollama无疑是一个值得尝试的工具，让我们一起探索AI的无限可能！

结合之前的介绍，Ollama现在不仅提供了一个稳定且功能丰富的平台来运行和管理大型模型，还通过其新特性，进一步拓宽了其在多用户协作和企业级应用中的潜力。尝试Ollama，体验本地部署大型模型的便捷与强大功能吧。
