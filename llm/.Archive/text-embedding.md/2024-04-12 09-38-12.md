---
title: 文本嵌入(Text Embeddings)
date: 2024-04-12 09:13
---
关键词搜索(Keyword Search)的技术，它通过计算问题和文档中重复词汇的数量，来搜索与问题相关的文档，常用的关键词搜索算法是Okapi BM25，简称BM25，关键词搜索算法的局限性在与它并不是根据文本本身的语义来进行文档搜索的，当文档与问题在语义上相关，但它们之间却没有重复词汇时，关键词搜索算法失效，它将无法搜索到该相关文档。为了解决这个问题，我们应该让机器理解文本本身的语义，然后根据文本的语义去搜索相关文档，这就引出了下面我们要解释的文本嵌入(Text Embeddings)的概念。

# 一、环境配置
我们需要安装如下的python包：
``` python
pip install cohere umap-learn altair datasets
```
这里简单介绍一下cohere是一家从事大模型应用开发的公司，接下来我们需要导入一些基础配置，这些基础配置主要包含cohere的api_key：
```python
import os
import cohere
import pandas as pd
from dotenv import load_dotenv, find_dotenv
```

##导入cohere的api_key
```
_ = load_dotenv(find_dotenv()) # read local .env file
```
 
##创建cohere的Client
```
co = cohere.Client(os.environ['COHERE_API_KEY'])
```
这里需要说明一下的是关于COHERE_API_KEY我们需要去cohere的网站自己注册一个cohere账号然后自己创建一个自己的api_key。

# 二、词嵌入(Word Embedding)
要了解什么是词嵌入，我们先来看下面这个例子，我们有一个二维的网格坐标图，上面摆放了各种物品，接下来我想要将一个apple(苹果)放入到这个网格中，请选择一个合适的位置，如下图所示：
![](/_image/2024-04-12/2024-04-12-09-16-43@2x.jpg)
仔细观察这个网格，在左上角是各种球类，左下角是各种建筑，右下角是各种交通工具,而右上角是各种水果，很显然apple应该放入到右上角，因为它属于水果，所以apple需要远离球类，建筑，交通工具,它需要和水果类的物品放在一起，最合适的位置应该是(5,5），如下图所示：
![](/_image/2024-04-12/2024-04-12-09-37-00@2x.jpg)
将一个词汇放入到词向量空间中的一个合适的位置这就是所谓的词嵌入(Word Embedding) ，在上图中我们用两个数值表示一个词汇在二维平面中的位置如apple(5,5)，banana(6,5)，car(6,0)等，但在实际的应用中一个词汇可能需要使用几百个，甚至几千个数字来表示其在多维空间中的位置,如下图所示:
![](/_image/2024-04-12/2024-04-12-09-37-16@2x.jpg)
一个好的词嵌入应该具备以下一些性质：

性质1：含义相似的词汇它们在多维空间中的位置应该相互接近（或者说它们有较高的相似度的分数）。
性质2：含义不同的词汇它们在多维空间中的位置应该相互远离（或者说它们有较底的相似度的分数）。
词嵌入与词汇的特征的捕捉
上面介绍的关于词嵌入的例子似乎满足了性质1和性质2，但这远远还不够，因为它只捕捉了词义的相似性特征，在一般情况下我们需要捕捉词汇中的更多特征，在自然语言中，单词可以组合起来得到更复杂的含义。在数学中，数字可以相加或相减得到其他数字。我们能否构建一个词嵌入来捕获单词之间的关系，就像数字之间的关系一样？

让我们看一下这四个单词：“Puppy(小狗)”、“Dog(狗)”、“Calf(小牛)”和“Cow(牛)”。这些单词之间有着明显的相关性。现在我们将在平面网格中放入单词“Puppy”、“Dog”和“Calf”，然后希望您在网格中添加单词“Cow”。现在有三个可以先选择的位置 A、B 或 C 的位置，你会选择哪一个？
![](/_image/2024-04-12/2024-04-12-09-37-33@2x.jpg)
您可能会将“Cow(牛)”放入到位置 A 中，因为这样它会更接近“Calf(小牛)”，因为它们都是牛，或者放到位置在 B 中，因为它是成年动物，如“Dog(狗)”，但最合理的位置应该是C ，即坐标[3,4]。因为这四个词形成的矩形平面体现了词汇之间的一些非常重要的关系。例如，这里会有两个类比。类比“小狗之于狗，就像小牛之于牛”可以理解为“从单词“Puppy(小狗)”到单词“Dog(狗)”的路径与从单词“Calf(小牛)”到单词“Cow(牛)”的路径相同”。“狗之于牛，就像小狗之于小牛”的类比也体现在这个矩形中，如下图所示：
![](/_image/2024-04-12/2024-04-12-09-37-50@2x.jpg)
然而，这还不足以成为冰山一角。此处词嵌入的主要属性是两个轴（垂直和水平）它们代表不同的含义。仔细看，向右移动，小狗变成了狗，小牛变成了牛，这是随年龄的增长产生的变化。同样，向上移动会将小狗变成小牛，将狗变成牛，这是随动物体型的增大产生的变化。因此这种嵌入是在理解了单词包含的两个主要属性或特征：年龄和大小。此外，词嵌入似乎将年龄定位在横轴上，将大小定位在竖轴上。那么，你会想象“whale(鲸鱼)”这个词应该放置在什么位置？可能在“Cow(牛)”这个词上面的某个地方。如果有一个词可以形容“一条老狗”呢？这个词会出现在“dog”这个词右边的某个地方：

![](/_image/2024-04-12/2024-04-12-09-38-11@2x.jpg)


