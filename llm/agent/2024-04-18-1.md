## GPT中的 function_call 功能调用详解

## 一、前言

最近GPT API 新增了部分的模型以及相关的API功能，部分模型包括gpt-3.5-turbo-16k、gpt-3.5-turbo-0613、gpt-3.5-turbo-16k-0613，以及对应的GPT4的相关模型。

另外大家都指导对应对于langchain中的agent，最神奇的功能就是使用工具，因此openai收到该功能的影响，将其自动集成进来，我们现在先看下有关langchain调用工具的基本逻辑是如何的。

### 二、API使用介绍

`functions` 是聊天完成API中的一个可选参数，可用于提供函数规范。这样做的目的是为了使模型能够生成符合所提供规格的函数参数。注意，该API不会实际执行任何函数调用。使用模型输出来执行函数调用是由开发者决定的。因此关键是如何生成对应工具函数的参数，使用该参数来执行调用函数，并将其结果返回。

如果提供 `functions` 参数，那么默认情况下，模型将决定何时适合使用其中一个函数。可以通过将 `function_call` 参数设置为 `{"name": "<insert-function-name>"}` 来强制API使用某个特定函数。也可以通过将 `function_call` 参数设为 `"none"` 来强制API不使用任何函数。如果使用了某个函数，输出结果将包含 `"finish_reason": "function_call"` ，以及一个包含函数名称和生成的函数参数的 `function_call` 对象。

### 三、function_call 的使用

对于大语言使用工具，之前一直有一个误区，总觉得LLM会直接执行工具，并通过观察工具返回的结果来组织总结语言。这一点主要是由于langchain过于集成封装化的语言造成的，这就导致了每次使用缺少对调用细节的理解，接下来就使用原始的API调用方法来实现对于工具的调用的过程。主要分为两部分，第一部分使用模型输出函数调用的参数。第二部分是根据模型输出的参数由开发者决定执行，并将执行的结果返回给llm模型。

### 3.1 生成函数参数

1. 导入第三方库

```python
import json
import openai
import requests
from tenacity import retry, wait_random_exponential, stop_after_attempt
from termcolor import colored
functions = [
    {
        "name": "get_current_weather", # 函数名，注意不要有空格
        "description": "Get the current weather", # 函数的描述
        "parameters": { # 函数的参数，对于输入的要求和每个输入的描述
            "type": "object",
            "properties": {
                "location": {
                    "type": "string", # 类型
                    "description": "The city and state, e.g. San Francisco, CA",# 描述
                },
                "format": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "The temperature unit to use. Infer this from the users location.",
                },
            },
            "required": ["location", "format"],# 哪些参数需要
        },
    },
    {
        "name": "get_n_day_weather_forecast",
        "description": "Get an N-day weather forecast",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "The city and state, e.g. San Francisco, CA",
                },
                "format": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "The temperature unit to use. Infer this from the users location.",
                },
                "num_days": {
                    "type": "integer",
                    "description": "The number of days to forecast",
                }
            },
            "required": ["location", "format", "num_days"]
        },
    },
]
```

### 3.2 构建大语言模型

1. 构建函数的形式

```python
messages = [] # 构建对话
messages.append({"role": "system", "content": "不要假设在函数中插入什么值。要求询问当用户请求是否含糊不清。"})
messages.append({"role": "user", "content": "今天天气怎么样"})
# 调用执行，传递messages的内容和调用的工具
chat_response = chat_completion_request(
    messages, functions=functions
)
# 获取模型返回结果，加入上下文中
assistant_message = chat_response.json()["choices"][0]["message"]
messages.append(assistant_message)
assistant_message
```

内部参数 `chat_response.json()` 的情况

```python
{'id': 'chatcmpl-7T9GrorQDgLtCL5vuQ7SqjZC6Gv0X', 'object': 'chat.completion', 'created': 1687181505, 'model': 'gpt-4-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '为了提供准确的天气信息，我需要知道您的位置。请问你在哪个城市？'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 211, 'completion_tokens': 32, 'total_tokens': 243}}
```

我分别使用了两个模型，一个是`gpt-4-0613`,一个是`gpt-3.5-0613`;使用这两个模型分别调用，返回结果如下所示。

```python
# GPT4能够返回询问我所在的城市
{'role': 'assistant', 'content': '为了提供准确的天气信息，我需要知道您的位置。请问你在哪个城市？'}
# GPT3.5 直接调用了function，默认城市在北京，推测可能是由于我使用了中文的关系
{'role': 'assistant',
 'content': None,
 'function_call': {'name': 'get_current_weather',
  'arguments': '{\n  "location": "北京",\n  "format": "celsius"\n}'}}

# 可通过继续增加messages中的内容来进行新增指定城市
messages.append({"role": "user", "content": "I'm in Glasgow, Scotland."})
```

1. 查看对话内容

最后通过指定打印messages来查看，对话的内容记录。

```python
[{'role': 'system', 'content': '不要假设在函数中插入什么值。要求仔细询问用户的意图当用户请求是否含糊不清。'},
 {'role': 'user', 'content': '今天天气怎么样'},
 {'role': 'assistant',
  'content': None,
  'function_call': {'name': 'get_current_weather',
   'arguments': '{\n  "location": "北京",\n  "format": "celsius"\n}'}}]
```

### 3.2 定义执行函数function_call的方法

由于大语言模型只能根据给定的工具的描述和输入输出的描述来返回相应的内容，因此，我们需要根据讲大语言模型返回的内容，传入函数中进行自动的执行自定义工具。这就完成了agent的闭环工作。

```python
def execute_function_call(message):
    if message["function_call"]["name"] == "get_current_weather":
        location = json.loads(message["function_call"]["arguments"])["location"]
        format = json.loads(message["function_call"]["arguments"])["format"]
        results = get_current_weather(location, format)
    else:
        results = f"Error: function {message['function_call']['name']} does not exist"
    return results
```

新增`get_current_weather`函数的内容

```python
def get_current_weather(location,format):
    return '40'
```

执行函数

```python
if assistant_message.get("function_call"):
    results = execute_function_call(assistant_message)
    messages.append({"role": "function", "name": assistant_message["function_call"]["name"], "content": results})
```

调用message显示结果如下所示

```python
[{'role': 'system', 'content': '不要假设在函数中插入什么值。要求仔细询问用户的意图当用户请求是否含糊不清。'},
 {'role': 'user', 'content': '今天天气怎么样'},
 {'role': 'assistant',
  'content': None,
  'function_call': {'name': 'get_current_weather',
   'arguments': '{\n  "location": "北京",\n  "format": "celsius"\n}'}},
 {'role': 'function', 'name': 'get_current_weather', 'content': '40'}]
```

可以看到能够很好的显示对话的内容结果。

### 四、langchain中的集成使用

langchain 第一时间接入了function_call的功能，新增了agent的类型为`OPENAI_FUNCTIONS`

最快速上手的代码如下所示，需要定义工具

```python
# 加载 modules
from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from langchain.llms import OpenAI
# 加载使用工具
llm = OpenAI(temperature=0)
tools = load_tools(["serpapi", "llm-math"], llm=llm)
# 定义agent
agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)
# 测试
agent.run("鹿晗的女朋友的年龄是多少，再乘积0.5等于多少")
```

后续的调用结果显示如下所示，显示排版结果是使用md格式排版的。

> Entering new chain...

Invoking: `Search` with `鹿晗女朋友年龄`

这个小编可以解答，虽然关晓彤是童星出身，但是1997年出生的她今年也满20岁了，谈恋爱再正常不过。 小编顺便说下，鹿晗是1990年出生，两人年龄相差7岁，这算是老少恋了吧！ Invoking: `Calculator` with `20 * 0.5`

> Entering new chain... 20 * 0.5```text 20 * 0.5

```python
...numexpr.evaluate("20 * 0.5")...

Answer: 10.0
> Finished chain.
Answer: 10.0鹿晗的女朋友的年龄是20岁，乘以0.5等于10岁。

> Finished chain.

进程已结束,退出代码0
```

### 五、参考资料

[https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_for_knowledge_retrieval.ipynb](https://link.zhihu.com/?target=https%3A//github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_for_knowledge_retrieval.ipynb)

[https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb](https://link.zhihu.com/?target=https%3A//github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb)

[LangChain](https://www.zhihu.com/topic/27269779)

[ChatGPT](https://www.zhihu.com/topic/26691895)

[Python](https://www.zhihu.com/topic/19552832)
